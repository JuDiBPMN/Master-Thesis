import os
import json
import xml.etree.ElementTree as ET
from xml.dom import minidom
from collections import defaultdict, deque

# ── Namespace constants ────────────────────────────────────────────────────────
BPMN   = "http://www.omg.org/spec/BPMN/20100524/MODEL"
BPMNDI = "http://www.omg.org/spec/BPMN/20100524/DI"
DC     = "http://www.omg.org/spec/DD/20100524/DC"
DI     = "http://www.omg.org/spec/DD/20100524/DI"

def tag(ns, local):
    return f"{{{ns}}}{local}"

NODE_SIZE = {
    "startEvent":               (36, 36),
    "endEvent":                 (36, 36),
    "intermediateCatchEvent":   (36, 36),
    "intermediateThrowEvent":   (36, 36),
    "exclusiveGateway":         (50, 50),
    "parallelGateway":          (50, 50),
    "inclusiveGateway":         (50, 50),
    "eventBasedGateway":        (50, 50),
}
DEFAULT_NODE_SIZE = (100, 80)

LANE_HEIGHT   = 160   # height of each individual lane
POOL_HEIGHT   = 200   # fallback when no lanes
POOL_WIDTH    = 900
POOL_HEADER_W = 30    # vertical label strip on left of pool
LANE_HEADER_W = 30    # vertical label strip on left of each lane
H_GAP         = 160

EVENT_DEFS = {
    "message":     "messageEventDefinition",
    "timer":       "timerEventDefinition",
    "signal":      "signalEventDefinition",
    "conditional": "conditionalEventDefinition",
    "error":       "errorEventDefinition",
    "escalation":  "escalationEventDefinition",
    "link":        "linkEventDefinition",
}

# ── Validation ────────────────────────────────────────────────────────────────

def validate(json_data):
    errors   = []
    warnings = []

    declared_participant_ids = {p["id"] for p in json_data.get("participants", [])}

    # Build lane id -> participant id map for validation
    declared_lane_ids = {}
    for p in json_data.get("participants", []):
        for lane in p.get("lanes", []):
            declared_lane_ids[lane["id"]] = p["id"]

    all_nodes         = _get_all_nodes(json_data)
    declared_node_ids = {n["id"] for n in all_nodes}

    for n in all_nodes:
        pid = n.get("participant")
        if not pid:
            errors.append(f"  [NODE '{n['id']}'] missing 'participant' field.")
        elif pid not in declared_participant_ids:
            errors.append(
                f"  [NODE '{n['id']}'] participant='{pid}' is not declared in "
                f"'participants'. Declared: {sorted(declared_participant_ids)}"
            )
        # Validate lane reference if present
        lane_id = n.get("lane")
        if lane_id:
            if lane_id not in declared_lane_ids:
                errors.append(
                    f"  [NODE '{n['id']}'] lane='{lane_id}' is not declared "
                    f"in any participant's lanes."
                )
            elif declared_lane_ids[lane_id] != pid:
                errors.append(
                    f"  [NODE '{n['id']}'] lane='{lane_id}' belongs to a "
                    f"different participant than '{pid}'."
                )

    node_to_pool = {n["id"]: n.get("participant") for n in all_nodes}

    for f in json_data.get("sequence_flows", []):
        for side in ("from", "to"):
            nid = f.get(side)
            if nid and nid not in declared_node_ids:
                errors.append(
                    f"  [SEQUENCE FLOW '{f.get('from')}'->'{ f.get('to')}'] "
                    f"'{side}' node '{nid}' does not exist."
                )

    for mf in json_data.get("message_flows", []):
        for side in ("from", "to"):
            nid = mf.get(side)
            if nid and nid not in declared_node_ids:
                errors.append(
                    f"  [MESSAGE FLOW '{mf.get('from')}'->'{ mf.get('to')}'] "
                    f"'{side}' node '{nid}' does not exist."
                )
        sp = node_to_pool.get(mf.get("from"))
        tp = node_to_pool.get(mf.get("to"))
        if sp and tp and sp == tp:
            warnings.append(
                f"  [MESSAGE FLOW '{mf.get('from')}'->'{ mf.get('to')}'] "
                f"both nodes are in pool '{sp}' — should be a sequence flow."
            )

    for f in json_data.get("sequence_flows", []):
        sp = node_to_pool.get(f.get("from"))
        tp = node_to_pool.get(f.get("to"))
        if sp and tp and sp != tp:
            warnings.append(
                f"  [SEQUENCE FLOW '{f.get('from')}'->'{ f.get('to')}'] "
                f"crosses pools ('{sp}'->'{tp}') — will be converted to a message flow."
            )

    pool_has_start = defaultdict(bool)
    for n in all_nodes:
        if n.get("type") == "startEvent":
            pool_has_start[n.get("participant")] = True
    for pid in declared_participant_ids:
        if not pool_has_start[pid]:
            warnings.append(
                f"  [POOL '{pid}'] has no startEvent — "
                f"bpmn.io will import it but the diagram will be incomplete."
            )

    pool_has_end = defaultdict(bool)
    for n in all_nodes:
        if n.get("type") == "endEvent":
            pool_has_end[n.get("participant")] = True
    for pid in declared_participant_ids:
        if not pool_has_end[pid]:
            warnings.append(
                f"  [POOL '{pid}'] has no endEvent — "
                f"bpmn.io will import it but the diagram will be incomplete."
            )

    if warnings:
        print("VALIDATION WARNINGS:")
        for w in warnings:
            print(w)
    if errors:
        print("VALIDATION ERRORS (must fix before XML will be valid):")
        for e in errors:
            print(e)
        return False

    if not warnings and not errors:
        print("  Validation passed.")
    return True

# ── Helpers ───────────────────────────────────────────────────────────────────

def _get_all_nodes(json_data):
    nodes = []
    for n in json_data.get("events",   []): nodes.append({**n, "_cat": "event"})
    for n in json_data.get("tasks",    []): nodes.append({**n, "_cat": "task"})
    for n in json_data.get("gateways", []): nodes.append({**n, "_cat": "gateway"})
    return nodes

def _build_participant_node_map(json_data):
    mapping = {p["id"]: [] for p in json_data.get("participants", [])}
    for n in _get_all_nodes(json_data):
        pid = n.get("participant")
        if pid in mapping:
            mapping[pid].append(n)
    return mapping

def _detect_cross_pool(json_data):
    node_to_pool = {n["id"]: n.get("participant") for n in _get_all_nodes(json_data)}
    seq_flows, promoted = [], []
    for f in json_data.get("sequence_flows", []):
        sp = node_to_pool.get(f["from"])
        tp = node_to_pool.get(f["to"])
        if sp and tp and sp != tp:
            promoted.append(f)
        else:
            seq_flows.append(f)
    return seq_flows, promoted

def _topological_order(node_ids, seq_flows):
    id_set = set(node_ids)
    flows  = [f for f in seq_flows
              if f["from"] in id_set and f["to"] in id_set]

    in_degree  = defaultdict(int)
    successors = defaultdict(list)
    for f in flows:
        successors[f["from"]].append(f["to"])
        in_degree[f["to"]] += 1

    queue = deque(n for n in node_ids if in_degree[n] == 0)
    order = []
    while queue:
        n = queue.popleft()
        order.append(n)
        for s in successors[n]:
            in_degree[s] -= 1
            if in_degree[s] == 0:
                queue.append(s)

    seen = set(order)
    for n in node_ids:
        if n not in seen:
            order.append(n)
    return order

# ── Core builder ──────────────────────────────────────────────────────────────

def create_bpmn_xml(json_data, output_path):

    ET.register_namespace("bpmn",   BPMN)
    ET.register_namespace("bpmndi", BPMNDI)
    ET.register_namespace("dc",     DC)
    ET.register_namespace("di",     DI)

    participants = json_data.get("participants", [])
    seq_flows, promoted = _detect_cross_pool(json_data)

    message_flows = list(json_data.get("message_flows", [])) + [
        {**f, "name": f.get("condition", "message"), "id": f"MsgFlow_promoted_{i}"}
        for i, f in enumerate(promoted)
    ]

    has_collaboration = len(participants) > 1 or bool(message_flows)
    collab_id = "Collaboration_1"

    # ── Root ──────────────────────────────────────────────────────────────────
    root = ET.Element(tag(BPMN, "definitions"), {
        "id": "Definitions_1",
        "targetNamespace": "http://bpmn.io/schema/bpmn",
        "exporter": "BPMN Pipeline",
        "exporterVersion": "1.0",
    })

    # ── Collaboration ─────────────────────────────────────────────────────────
    if has_collaboration:
        collaboration = ET.SubElement(root, tag(BPMN, "collaboration"), id=collab_id)

        for p in participants:
            ET.SubElement(collaboration, tag(BPMN, "participant"), {
                "id":         f"Participant_{p['id']}",
                "name":       p["name"],
                "processRef": f"Process_{p['id']}",
            })

        for i, mf in enumerate(message_flows):
            ET.SubElement(collaboration, tag(BPMN, "messageFlow"), {
                "id":        mf.get("id", f"MsgFlow_{i}"),
                "name":      mf.get("name", ""),
                "sourceRef": mf["from"],
                "targetRef": mf["to"],
            })

    # ── One <process> per participant ─────────────────────────────────────────
    participant_node_map = _build_participant_node_map(json_data)
    process_map   = {}
    node_type_map = {}

    for p in participants:
        proc_id   = f"Process_{p['id']}"
        proc_elem = ET.SubElement(root, tag(BPMN, "process"), {
            "id":           proc_id,
            "name":         p["name"],
            "isExecutable": "false",
        })
        process_map[p["id"]] = proc_elem

        lanes = p.get("lanes", [])

        # ── laneSet (only if lanes are declared) ──────────────────────────────
        if lanes:
            lane_set_elem = ET.SubElement(proc_elem, tag(BPMN, "laneSet"),
                                          id=f"LaneSet_{p['id']}")
            # Build a map of lane_id -> list of node ids in that lane
            lane_node_map = defaultdict(list)
            for n in participant_node_map.get(p["id"], []):
                lid = n.get("lane")
                if lid:
                    lane_node_map[lid].append(n["id"])

            for lane in lanes:
                lane_elem = ET.SubElement(lane_set_elem, tag(BPMN, "lane"), {
                    "id":   lane["id"],
                    "name": lane["name"],
                })
                # flowNodeRef: tell BPMN which nodes live in this lane
                for nid in lane_node_map.get(lane["id"], []):
                    ref = ET.SubElement(lane_elem, tag(BPMN, "flowNodeRef"))
                    ref.text = nid

        # ── Nodes ─────────────────────────────────────────────────────────────
        for n in participant_node_map.get(p["id"], []):
            n_id, n_name, n_type = n["id"], n["name"], n["type"]
            node_type_map[n_id] = n_type

            elem = ET.SubElement(proc_elem, tag(BPMN, n_type), id=n_id, name=n_name)

            if n["_cat"] == "event":
                ev_def = n.get("eventDefinition", "none")
                if ev_def and ev_def != "none":
                    child = EVENT_DEFS.get(ev_def)
                    if child:
                        ET.SubElement(elem, tag(BPMN, child), id=f"{n_id}_def")

            if n["_cat"] == "gateway":
                elem.set("gatewayDirection", n.get("gatewayDirection", "diverging"))

        # ── Sequence flows ────────────────────────────────────────────────────
        pool_node_ids = {n["id"] for n in participant_node_map.get(p["id"], [])}
        for i, flow in enumerate(seq_flows):
            if flow["from"] not in pool_node_ids:
                continue
            attrs = {
                "id":        flow.get("id", f"Flow_{i}"),
                "sourceRef": flow["from"],
                "targetRef": flow["to"],
            }
            if flow.get("condition"):
                attrs["name"] = flow["condition"]
            sf = ET.SubElement(proc_elem, tag(BPMN, "sequenceFlow"), attrs)
            if flow.get("condition"):
                cond = ET.SubElement(sf, tag(BPMN, "conditionExpression"))
                cond.text = flow["condition"]

    # ── Layout computation ─────────────────────────────────────────────────────
    # For pools with lanes: each lane gets its own horizontal band.
    # node_layout stores absolute canvas coordinates for every node.
    pool_layout  = {}   # pid  -> {x, y, w, h}
    lane_layout  = {}   # lid  -> {x, y, w, h}
    node_layout  = {}   # nid  -> {x, y, w, h}
    current_pool_y = 20

    for p in participants:
        lanes      = p.get("lanes", [])
        all_nodes_in_pool = participant_node_map.get(p["id"], [])
        id_to_node = {n["id"]: n for n in all_nodes_in_pool}

        if lanes:
            # Pool height = sum of lane heights
            total_pool_h = len(lanes) * LANE_HEIGHT
            pool_w = max(POOL_WIDTH,
                         POOL_HEADER_W + LANE_HEADER_W + 60 +
                         max((len([n for n in all_nodes_in_pool
                                   if n.get("lane") == ln["id"]])
                              for ln in lanes), default=1) * H_GAP + 60)

            pool_layout[p["id"]] = {
                "x": 10, "y": current_pool_y,
                "w": pool_w, "h": total_pool_h,
            }

            lane_y = current_pool_y
            for lane in lanes:
                lane_layout[lane["id"]] = {
                    "x": 10 + POOL_HEADER_W,   # sits to the right of pool header
                    "y": lane_y,
                    "w": pool_w - POOL_HEADER_W,
                    "h": LANE_HEIGHT,
                }

                # Nodes in this lane — topological order within lane
                lane_node_ids = [n["id"] for n in all_nodes_in_pool
                                 if n.get("lane") == lane["id"]]
                ordered_ids   = _topological_order(lane_node_ids, seq_flows)

                node_x = 10 + POOL_HEADER_W + LANE_HEADER_W + 40
                for nid in ordered_ids:
                    n    = id_to_node[nid]
                    w, h = NODE_SIZE.get(n["type"], DEFAULT_NODE_SIZE)
                    ny   = lane_y + (LANE_HEIGHT - h) // 2
                    node_layout[nid] = {"x": node_x, "y": ny, "w": w, "h": h}
                    node_x += H_GAP

                # Nodes with no lane assignment fall through to here — place them too
                lane_y += LANE_HEIGHT

            # Any nodes without a lane: place them below all lanes
            unlaned = [n for n in all_nodes_in_pool if not n.get("lane")]
            if unlaned:
                ordered_unlaned = _topological_order([n["id"] for n in unlaned], seq_flows)
                node_x = 10 + POOL_HEADER_W + 60
                for nid in ordered_unlaned:
                    n    = id_to_node[nid]
                    w, h = NODE_SIZE.get(n["type"], DEFAULT_NODE_SIZE)
                    ny   = current_pool_y + (total_pool_h - h) // 2
                    node_layout[nid] = {"x": node_x, "y": ny, "w": w, "h": h}
                    node_x += H_GAP

            current_pool_y += total_pool_h + 20

        else:
            # No lanes — original flat layout
            raw_ids     = [n["id"] for n in all_nodes_in_pool]
            ordered_ids = _topological_order(raw_ids, seq_flows)

            pool_w = max(POOL_WIDTH,
                         POOL_HEADER_W + 60 + len(ordered_ids) * H_GAP + 60)
            pool_layout[p["id"]] = {
                "x": 10, "y": current_pool_y, "w": pool_w, "h": POOL_HEIGHT,
            }

            node_x = POOL_HEADER_W + 60
            for nid in ordered_ids:
                n    = id_to_node[nid]
                w, h = NODE_SIZE.get(n["type"], DEFAULT_NODE_SIZE)
                ny   = current_pool_y + (POOL_HEIGHT - h) // 2
                node_layout[nid] = {"x": node_x, "y": ny, "w": w, "h": h}
                node_x += H_GAP

            current_pool_y += POOL_HEIGHT + 20

    # ── BPMNDI ────────────────────────────────────────────────────────────────
    bpmndi_elem = ET.SubElement(root, tag(BPMNDI, "BPMNDiagram"), id="BPMNDiagram_1")
    plane_ref   = collab_id if has_collaboration else \
                  (f"Process_{participants[0]['id']}" if participants else "Process_1")
    plane = ET.SubElement(bpmndi_elem, tag(BPMNDI, "BPMNPlane"),
                          id="BPMNPlane_1", bpmnElement=plane_ref)

    # Pool shapes (only when collaboration exists)
    if has_collaboration:
        for p in participants:
            pl = pool_layout[p["id"]]
            shape = ET.SubElement(plane, tag(BPMNDI, "BPMNShape"), {
                "id":           f"Participant_{p['id']}_di",
                "bpmnElement":  f"Participant_{p['id']}",
                "isHorizontal": "true",
            })
            ET.SubElement(shape, tag(DC, "Bounds"),
                          x=str(pl["x"]), y=str(pl["y"]),
                          width=str(pl["w"]), height=str(pl["h"]))

    # Lane shapes
    for p in participants:
        for lane in p.get("lanes", []):
            ll = lane_layout[lane["id"]]
            shape = ET.SubElement(plane, tag(BPMNDI, "BPMNShape"), {
                "id":           f"{lane['id']}_di",
                "bpmnElement":  lane["id"],
                "isHorizontal": "true",
            })
            ET.SubElement(shape, tag(DC, "Bounds"),
                          x=str(ll["x"]), y=str(ll["y"]),
                          width=str(ll["w"]), height=str(ll["h"]))

    # Node shapes
    for n_id, layout in node_layout.items():
        n_type = node_type_map.get(n_id, "")
        attrs  = {"id": f"{n_id}_di", "bpmnElement": n_id}
        if "Gateway" in n_type:
            attrs["isMarkerVisible"] = "true"
        shape = ET.SubElement(plane, tag(BPMNDI, "BPMNShape"), attrs)
        ET.SubElement(shape, tag(DC, "Bounds"),
                      x=str(layout["x"]), y=str(layout["y"]),
                      width=str(layout["w"]), height=str(layout["h"]))

    # Sequence flow edges
    for i, flow in enumerate(seq_flows):
        src, tgt = flow["from"], flow["to"]
        if src not in node_layout or tgt not in node_layout:
            continue
        s = node_layout[src]
        t = node_layout[tgt]
        edge = ET.SubElement(plane, tag(BPMNDI, "BPMNEdge"), {
            "id":          f"{flow.get('id', f'Flow_{i}')}_di",
            "bpmnElement": flow.get("id", f"Flow_{i}"),
        })
        ET.SubElement(edge, tag(DI, "waypoint"),
                      x=str(s["x"] + s["w"]), y=str(s["y"] + s["h"] // 2))
        ET.SubElement(edge, tag(DI, "waypoint"),
                      x=str(t["x"]),           y=str(t["y"] + t["h"] // 2))

    # Message flow edges
    node_to_pool_id = {n["id"]: n.get("participant") for n in _get_all_nodes(json_data)}

    for i, mf in enumerate(message_flows):
        src, tgt = mf["from"], mf["to"]
        if src not in node_layout or tgt not in node_layout:
            continue
        s  = node_layout[src]
        t  = node_layout[tgt]
        sp = node_to_pool_id.get(src)
        tp = node_to_pool_id.get(tgt)

        src_pool_y = pool_layout[sp]["y"] if sp in pool_layout else 0
        tgt_pool_y = pool_layout[tp]["y"] if tp in pool_layout else 0

        if src_pool_y < tgt_pool_y:
            wx1, wy1 = s["x"] + s["w"] // 2, s["y"] + s["h"]
            wx2, wy2 = t["x"] + t["w"] // 2, t["y"]
        else:
            wx1, wy1 = s["x"] + s["w"] // 2, s["y"]
            wx2, wy2 = t["x"] + t["w"] // 2, t["y"] + t["h"]

        edge = ET.SubElement(plane, tag(BPMNDI, "BPMNEdge"), {
            "id":          f"{mf.get('id', f'MsgFlow_{i}')}_di",
            "bpmnElement": mf.get("id", f"MsgFlow_{i}"),
        })
        ET.SubElement(edge, tag(DI, "waypoint"), x=str(wx1), y=str(wy1))
        ET.SubElement(edge, tag(DI, "waypoint"), x=str(wx2), y=str(wy2))

    # ── Serialise ─────────────────────────────────────────────────────────────
    xml_bytes  = ET.tostring(root, encoding="utf-8", xml_declaration=False)
    pretty_xml = minidom.parseString(xml_bytes).toprettyxml(indent="  ")
    lines      = pretty_xml.splitlines()
    final      = '<?xml version="1.0" encoding="UTF-8"?>\n' + \
                 "\n".join(l for l in lines if not l.startswith("<?xml"))

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(final)
    print(f"  Written -> {output_path}")


# ── Entry point ───────────────────────────────────────────────────────────────

if __name__ == "__main__":
    # --- CONFIGURATION ---
    case_name          = "case_1"
    pipeline_name      = "direct_extraction_pipeline"
    prompting_strategy = "few_shot"
    # ---------------------

    SCRIPT_DIR   = os.path.dirname(os.path.abspath(__file__))
    PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)

    JSON_SOURCE_DIR = os.path.join(PROJECT_ROOT, "pipelines", pipeline_name, "outputs")
    XML_OUTPUT_DIR  = os.path.join(SCRIPT_DIR, "outputs")
    os.makedirs(XML_OUTPUT_DIR, exist_ok=True)

    input_json_path = os.path.join(JSON_SOURCE_DIR,
                                   f"{case_name}_{prompting_strategy}_bpmn_invalid.json")
    output_xml_path = os.path.join(XML_OUTPUT_DIR,
                                   f"{case_name}_{prompting_strategy}.bpmn")

    print("--- BPMN XML Generator ---")

    try:
        if not os.path.exists(input_json_path):
            raise FileNotFoundError(f"Input file not found: {input_json_path}")

        with open(input_json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        print("Validating JSON...")
        if not validate(data):
            print("Fix the errors above in your JSON before generating XML.")
        else:
            create_bpmn_xml(data, output_xml_path)
            print("Success - upload the .bpmn file to https://bpmn.io")

    except Exception as e:
        print(f"Error: {e}")